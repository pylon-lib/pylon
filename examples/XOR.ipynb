{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, w=None):\n",
    "        super().__init__()\n",
    "        if w is not None:\n",
    "            self.w = torch.nn.Parameter(torch.tensor(w).float().view(6, 1))\n",
    "        else:\n",
    "            self.w = torch.nn.Parameter(torch.rand(6, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(self.w, x).view(3, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plothelper import PlotHelper\n",
    "\n",
    "\n",
    "net = Net()\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "plot = PlotHelper()\n",
    "\n",
    "x = torch.tensor([1.])\n",
    "y = torch.tensor([0, 0, 1])\n",
    "\n",
    "for _ in range(100):\n",
    "    opt.zero_grad()\n",
    "    y_logit = net(x)\n",
    "    loss = F.cross_entropy(y_logit[2:], y[2:])\n",
    "    loss.backward()\n",
    "    y_prob = torch.softmax(y_logit, dim=-1)\n",
    "    plot.add(y0=y_prob[0,1].data, y1=y_prob[1,1].data, y2=y_prob[2,1].data, loss=loss.data)\n",
    "    opt.step()\n",
    "\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from plothelper import PlotHelper\n",
    "from pytorch_constraints.constraint import constraint\n",
    "from pytorch_constraints.brute_force_solver import *\n",
    "from pytorch_constraints.sampling_solver import *\n",
    "from pytorch_constraints.tnorm_solver import ProductTNormLogicSolver\n",
    "\n",
    "net = Net()\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "plot = PlotHelper()\n",
    "plot_loss = PlotHelper()\n",
    "\n",
    "\n",
    "# y: 3, Bx3\n",
    "def xor(y):\n",
    "    # return (y[0] and not y[2]) or (not y[0] and y[2])\n",
    "    return y[0]!=y[1] and y[1]!=y[2]\n",
    "    # return any([y[i]==y[i-1] for i in range(10)])\n",
    "\n",
    "# xor_cons = constraint(xor)\n",
    "num_samples = 100\n",
    "xor_cons = constraint(xor, ViolationBruteForceSolver())\n",
    "# xor_cons = constraint(xor, SamplingSolver(num_samples))\n",
    "# xor_cons = constraint(xor, WeightedSamplingSolver(num_samples))\n",
    "#xor_cons = constraint(xor, ProductTNormLogicSolver())\n",
    "# x: 1 -> Bx1\n",
    "for _ in range(500):\n",
    "    opt.zero_grad()\n",
    "    y_logit = net(x) # y: 3x2 -> Bx3x2\n",
    "    oloss = F.cross_entropy(y_logit[2:], y[2:])\n",
    "    closs = xor_cons(y_logit)\n",
    "    loss = oloss + closs\n",
    "    loss.backward()\n",
    "    y_prob = torch.softmax(y_logit, dim=-1)\n",
    "    plot.add(y0=y_prob[0,1].data, y1=y_prob[1,1].data, y2=y_prob[2,1].data)\n",
    "    plot_loss.add(oloss=oloss.data, closs=closs.data, loss=loss.data)\n",
    "    opt.step()\n",
    "\n",
    "plot.show()\n",
    "plot_loss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BatchNet(torch.nn.Module):\n",
    "    def __init__(self, w=None):\n",
    "        super().__init__()\n",
    "        if w is not None:\n",
    "            self.w = torch.nn.Parameter(torch.tensor(w).float().view(6, 1))\n",
    "        else:\n",
    "            self.w = torch.nn.Parameter(torch.rand(6, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.w.T).view(-1, 3, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from plothelper import PlotHelper\n",
    "\n",
    "\n",
    "net = BatchNet()\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "plot0 = PlotHelper()\n",
    "plot1 = PlotHelper()\n",
    "\n",
    "x = torch.tensor([[1.],[1.]])\n",
    "y = torch.tensor([[0, 0, 1],[0, 0, 1]])\n",
    "\n",
    "for _ in range(100):\n",
    "    opt.zero_grad()\n",
    "    y_logit = net(x)\n",
    "    loss = F.cross_entropy(y_logit[:, 2:, :].view(-1, 2), y[:, 2:].view(-1,))\n",
    "    loss.backward()\n",
    "    y_prob = torch.softmax(y_logit, dim=-1)\n",
    "    plot0.add(y0=y_prob[0,0,1].data, y1=y_prob[0,1,1].data, y2=y_prob[0,2,1].data, loss=loss.data)\n",
    "    plot1.add(y0=y_prob[1,0,1].data, y1=y_prob[1,1,1].data, y2=y_prob[1,2,1].data, loss=loss.data)\n",
    "    opt.step()\n",
    "\n",
    "plot0.show()\n",
    "plot1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from plothelper import PlotHelper\n",
    "\n",
    "from pytorch_constraints.constraint import constraint\n",
    "from pytorch_constraints.brute_force_solver import ViolationBruteForceSolver\n",
    "\n",
    "\n",
    "net = BatchNet()\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "plot0 = PlotHelper()\n",
    "plot1 = PlotHelper()\n",
    "\n",
    "x = torch.tensor([[1.],[1.]])\n",
    "y = torch.tensor([[0, 0, 1],[0, 0, 1]])\n",
    "\n",
    "def xor(y):\n",
    "    return (y[:,0] and not y[:,2]) or (not y[:,0] and y[:,2])\n",
    "xor_cons = constraint(xor, ViolationBruteForceSolver())\n",
    "\n",
    "for _ in range(100):\n",
    "    opt.zero_grad()\n",
    "    y_logit = net(x)\n",
    "    oloss = F.cross_entropy(y_logit[:, 2:, :].view(-1, 2), y[:, 2:].view(-1,))\n",
    "    closs = xor_cons(y_logit, y_logit)\n",
    "    loss = oloss + closs\n",
    "    loss.backward()\n",
    "    y_prob = torch.softmax(y_logit, dim=-1)\n",
    "    plot0.add(y0=y_prob[0,0,1].data, y1=y_prob[0,1,1].data, y2=y_prob[0,2,1].data, loss=loss.data)\n",
    "    plot1.add(y0=y_prob[1,0,1].data, y1=y_prob[1,1,1].data, y2=y_prob[1,2,1].data, loss=loss.data)\n",
    "    opt.step()\n",
    "\n",
    "plot0.show()\n",
    "plot1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
